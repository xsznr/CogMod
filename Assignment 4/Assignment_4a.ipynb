{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4a Cognitive Modelling\n",
    "\n",
    "Dit is de eerste helft van de vierde opdracht voor Cognitive Modelling. Het totaal aantal punten dat je voor assignment 4a kan halen is __49 punten__.\n",
    "\n",
    "Bij elke vraag staat de hoeveelheid punten die je er voor kan krijgen. Geef antwoorden in blokken met code of met tekst. Gebruik voor antwoorden met tekst de \">\" voor blockquotes en geef bij elke vraag ook __kort uitleg__ als hier om wordt gevraagd. __Let op__: soms staan er meerdere vragen bij een onderdeel, lees de tekst dus nauwkeurig. \n",
    "\n",
    "Sla het uiteindelijke notebook op met jullie studentnummers en achternamen in de filenaam: `studentnummer_achternaam_opdrachtnummer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Part 1\n",
    "\n",
    "In reinforcement learning and artifical intelligence wordt eigenlijk maar weinig gekeken naar keuzes, ook al is het maken van eigen (goede?) keuzes een belangrijk aspect van mens zijn. Daarnaast weet iedereen dat kiezen helemaal niet altijd makkelijk is. In de meest algoritmes waar we nu naar hebben gekeken zag je dat er √≥f een exploratie keuze was √≥f simple max Q werd gekozen (de optie met de hoogste verwachte uitkomst). \n",
    "\n",
    "In de kleine werelden van spellen is vaak heel duidelijk gedefineerd wat de belonging is of hoeveel punten je ergens voor krijgt en is meer punten altijd beter dan minder. Maar in de echte wereld is dit niet altijd het geval en zijn gevolgen ook niet altijd even duidelijk. Ook hebben we in het morele domein gezien dat een simpele calculus (hoeveel doden vallen er in het trolly dilemma) niet altijd is hoe wij zouden willen dat een A.I. keuzes maakt. \n",
    "\n",
    "We gaan in onderstaande opdracht naar een aantal modelen kijken van keuze gedrag, dit moet je een idee geven hoe je dit zou kunnen implementeren.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 1. The pizza problem üçï\n",
    "\n",
    "Wat goed is, is vaak subjectief. Stel je voor dat het vrijdagavond is, en je favoriete pizzeria heeft een speciale aanbieding: twee 12 inch pizza's voor de prijs van √©√©n 18 inch pizza. Laat we voor het gemak zeggen dat een 18 inch pizza 10 euro kost. Wat zou jij kiezen? \n",
    "\n",
    "![](Images\\pizza_problem_guest_martin_2020.png)\n",
    "\n",
    "Is dit een goede aanbieding? Het antwoord is... dat ligt er aan. Deze vraag is eens op twitter gesteld en er kwamen verassend veel verschillende antwoorden (Guest & Martin, 2020). Sommige vonden van wel, andere hadden een goede reden waarom niet. Zo zei iemand dat twee pizzas meer is dan √©√©n, maar een ander zei dat de ene pizza in totaal meer pizza is dan de twee kleine samen.\n",
    "\n",
    "Welke optie je moet kiezen ligt er aan waar je het meeste waarde aan hecht, oftewel wat heeft het grootste nut (utilitiy)? \n",
    "\n",
    "<br>\n",
    "\n",
    "### Q1.a (3 pts)\n",
    "\n",
    "Schrijf een _Utilitiy Functie_ `def utility_area()` die het nut van een aantal pizza's berekent zoals sommige mensen dat doen: op basis van de totale oppervlakte. Welke optie zouden deze mensen kiezen: 2 pizza's van 12 inch, 1 pizza van 18 inch, of 3 pizza's van 10 inch?\n",
    "\n",
    "ps. 12\" pizza betekent een diameter van 12\" inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_area():\n",
    "    # TO DO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ik heb een theorie dat de mensen die voor twee pizza's zouden gaan in plaats van voor √©√©n pizza, de korst lekkerder vinden dan de binnenkant van de pizza. Ik wil kijken of deze theorie het gedrag van deze mensen kan verklaren.\n",
    "Het totale nut van een pizza is nu dus uitgedrukt in het nut (oppervlakte) van de korst plus het nut van de binnenkant van de pizza.\n",
    "\n",
    "### Q1.b (4 pts)\n",
    "Schrijf een _Utilitiy Functie_ `def utility_yummy_crust()` die personen beschrijft die een $x$ aantal keer meer houden van de korst dan van de binnenkant van de pizza.\n",
    "\n",
    "Laten we er van uit gaan dat de korst 1\" inch dik is. Hoeveel moet een persoon de korst op z'n minst lekkerder vinden om te kiezen voor de optie met twee pizzas? De utility (oppervlakte) van de korst is hierbij dus $x$ keer hoger dan de utility van de binnenkant. Een ongeveer antwoord is goed, maar je kan de parameter ook optimaliseren. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_yummy_crust():\n",
    "    # TO DO \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is slechts een hypothetisch voorbeeld over hoe je een psychologische theorie over keuzegedrag kan formaliseren in een wiskundige formule. Dit kan heel erg behulpzaam zijn want deze precieze voorspellingen kunnen makkelijk getoetst worden in de toekomst. \n",
    "\n",
    "### Q1.c (2 pts)\n",
    "Stel dat je nu tot de hypothese gekomen bent dat mensen de korst van de pizza 3 keer zo lekker vinden als de binnenkant. Zal deze persoon nog liever drie pizzas van 9 inch willen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Een loterij üí∞ \n",
    "\n",
    " Bijna alle keuzes in het dagelijks leven hebben een element van kans of onzekerheid. Op je fiets naar de campus, net oversteken bij het rode licht, etc. Je houding ten opzicht van risico's bepaalt ook veel van de keuzes die je in het leven maakt. Ga je een stage doen in het buitenland bij een onbekende groep? Of blijf je lekker op de vertrouwde campus?\n",
    "\n",
    "Zoals in het college besproken, worden loterijen vaak gebruikt om te bestuderen hoe mensen met risico en onzekerheid omgaan. De hoofdprijs uit de loterij is fantastisch, maar het is heel onzeker (de kans is klein) dat je deze ook echt krijgt. Hier gaan we kort kijken naar die modellen en toepassen op jouw eigen keuzes, om zo te begrip te krijgen hoe jij met risico/onzekerheid omgaat. \n",
    "\n",
    "### Mini-experiment\n",
    "In de bijlage `Risk_Q.pdf` vind je een lijst met keuzes tussen twee loterijen, zoals in het figuur hieronder. Voor elke loterij zijn er telkens twee mogelijke uitkomsten, aan jou de vraag welke loterij je zou kiezen als je er een moet uitkiezen. Kijk goed naar de uitkomsten en kansen en vink aan welke loterij je kiest.\n",
    "\n",
    "<img src=\"Images\\loterij.png\" style=\"width: 750px;\"/>\n",
    "\n",
    "\n",
    "### Q2 (5 pts)\n",
    "\n",
    "Als je alle keuzes gemaakt hebt, gebruik dan `data_self.txt` om je eigen keuzes op te slaan, onder jouw naam `studentnummer_data.txt`:\n",
    "\n",
    "        p1,o1,p2,o2: p's and o's of gamble 1  (p is probability, o is outcome)\n",
    "        p3,o3,p4,o4: p's and o's of gamble 2 \n",
    "        decision: choice (1 = gamble 1, 2 = gamble 2)\n",
    "\n",
    "<img src=\"Images\\example_data.png\" style=\"width: 650px;\"/>\n",
    "\n",
    "Zorg dat je dit databestand inlevert op Canvas, anders krijg je geen punten voor deze opdracht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Prospect Theory\n",
    "\n",
    "Prospect theory, ook wel cumulative prospect theory (CPT), is een theorie die beschrijft hoe mensen uitkomsten en waarschijnlijkheden wegen en tot een beslissing komen. Het gebruikt hiervoor een combinatie van vier verschillende functies:\n",
    "\n",
    "1. Een functie die objectieve uitkomsten transformeert naar subjectieve waarde $v(x)$\n",
    "2. Een functie die waarschijnlijkheid transformeert naar subjectieve waarschijnlijkheid $w(p)$\n",
    "3. Een functie die subjectieve waarden en waarschijnlijkheden van een optie integreert tot een subjectieve verwachte waarde (expected value) $EV(x)$\n",
    "4. Een beslis regel die uitrekent met welke waarschijnlijkheid een van twee opties wordt gekozen (in dit geval $P_x$) (de $U$ in de functie staat voor Utility, of expected value).\n",
    "\n",
    "<h1 style=\"background-color:LightGray;\"><img src=\"Images\\functions.png\"></h1>\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "### Q3.a (9 pts)\n",
    "\n",
    "Schrijf voor elke van deze 4 functies een functie in Python. Geef bij elke functie aan welke vrije variabelen deze heeft en wat die betekenen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpt_sub_value():\n",
    "    # TO DO\n",
    "    return\n",
    "    \n",
    "def cpt_prob_weight():\n",
    "    # TO DO\n",
    "    return\n",
    "\n",
    "def cpt_ev():\n",
    "    # TO DO\n",
    "    return\n",
    "\n",
    "def cpt_choice():\n",
    "    # TO DO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q3.b (4 pts)\n",
    "\n",
    "Plot de subjectieve waarde functie `cpt_sub_value` voor objectieve waardes tussen 0 en 1000, gebruik makende van verschillende waarden van $\\alpha$, elke in een aparte grafiek:\n",
    "\n",
    "$$\\alpha \\in \\{0.7, 1.3, 1.7\\}$$\n",
    "\n",
    "*Hint:* Gebruik [vectorize](https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html) om een bestaande functie op een gehele [ndarray](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) tegelijk te kunnen toepassen, en zo alle subjectieve waardes in 1 keer uit te rekenen. (zie onderstaand voorbeeld voor  alpha = 0.8)\n",
    "\n",
    "    vec_sub_value = np.vectorize(cpt_sub_value, excluded=[1,2,3])\n",
    "\n",
    "    x = np.array(range(1000))\n",
    "    for alpha in [0.8]:\n",
    "        y = vec_sub_value(x, alpha, 0, 0)\n",
    "        plt.plot(x, y, label=r'$\\alpha =$'+str(alpha))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "De meeste mensen zijn risicomijdend, welke grafiek beschrijft dus het best het gedrag van mensen? Leg uit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q3.c (4 pts)\n",
    "\n",
    "Plot de subjectieve waarde functie `cpt_sub_value` voor objectieve waardes tussen 0 en -1000, gebruik makende van verschillende waarden van $\\beta$ en $\\lambda$, en label deze lijnen voor:\n",
    "\n",
    "$$\\beta = 0.7$$\n",
    "$$\\lambda \\in \\{0.5, 1.5\\}$$\n",
    "\n",
    "De meeste mensen vinden verliezen van 200 euro relatief erger dan dat ze blij zijn met het winnen van 200 euro, dus welke waarde van $\\lambda$ pas het best bij menselijk gedrag? (hint kijk dus ook weer even naar grafiek met $\\alpha$ hierboven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q3.d (3 pts)\n",
    "\n",
    "Plot de waarschijnlijkheids functie `cpt_prob_weight` die waarschijnlijkheden tussen $0.1$ en $0.9$ omzet naar subjectieve waarschijnlijkheden, gebruik makende van verschillende waarden van $\\gamma = {0.5, 0.75, 1, 1.25, 1.5}$, en label deze lijnen.\n",
    "\n",
    "Wat staat er op de x-as? En op de y-as? Bij welke waarde(s) van gamma vind je het gebruikelijke patroon dat mensen laten zien? (zie grafiek in college slides, plot ook een identity line $(x=y)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_prob_weight = np.vectorize(cpt_prob_weight, excluded=[1])\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q3.e (3 pts)\n",
    "\n",
    "Laten we nu kijken naar hoe verschillende parameter waarden kunnen leiden tot verschillende keuzes. Laten we er voor het gemak even vanuit gaan dat de proefpersoon altijd simpelweg de optie kiest met de hoogste verwachtte uitkomst. Beschouw de volgende twee opties:\n",
    "\n",
    "    A: 1% kans op 1000 euro, en anders niets \n",
    "    B: 50% kans op 20 euro, en anders niets\n",
    "\n",
    "Vergelijk de uitkomsten voor de 4 mogelijke combinaties met $\\alpha \\in \\{0.3, 1.5\\}$ en $\\gamma \\in \\{0.5, 2.0\\}$ en vertel welke loterij verkozen wordt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Model fitting üèã\n",
    "\n",
    "We gaan nu kijken naar de resultaten van een echt experiment. We hebben de data van een aantal proefpersonen die een heel aantal loterijen heeft gespeeld. In de data file kunnen we terugvinden welke van 2 opties zij gekozen hebben. We gaan kijken hoe goed CPT het gedrag van de proefpersonen kan voorspellen, en wat voor een parameter waardes dit oplevert. De data file die we zullen gebruiken is `data_LC4.txt`:\n",
    "\n",
    "    Data Coding:\n",
    "    Subject: is subject nr.\n",
    "    p1,o1,p2,o2:    p's and o's of gamble 1  (p is probability, o is outcome)\n",
    "    p3,o3,p4,o4:    p's and o's of gamble 2 \n",
    "    decision:       choice (1 = gamble 1, 2 = gamble 2)\n",
    "   \n",
    "Elke gamble wordt beschreven, net als hierboven, door twee kansen en twee uitkomsten. \n",
    "Schrijf een `CPT_fit` functie zodat je deze op de data van de proefpersonen kan fitten. \n",
    "We gaan voor het fitten van het model gebruik maken van [optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) en we gaan proberen Log Likelihood te maximaliseren. Net als in de vorige notebooks. \n",
    "\n",
    "In het databestand van de proefpersoon kunnen we zien welke van de 2 loterijen de proefpersoon koos. Wat we op elke trial willen weten is wat de waarschijnlijkheid is dat het model dezelfde keuze maakt als de proefpersoon, gegeven de huidige parameter waardes. Hoe hoe groter die kans (likelihood) is hoe beter het model fit.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Q4.a (8 pts)\n",
    "\n",
    "Gebruik de onderstaande code en  functie `CPT_fit`. Deze functie kan worden gebruikt om de parameters van CPT te vinden die het best de keuzes van een persoon beschrijven.\n",
    "\n",
    "We gebruiken als startwaarden $\\alpha=0.5$, $\\beta=0.5$, $\\lambda=0.5$, $\\gamma=0.5$ en $\\theta=0.05$, en gebruik [Nelder-Mead](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-neldermead.html#optimize-minimize-neldermead) als de methode voor de minimalisatie.\n",
    "\n",
    "ps. RuntimeWarning: divide by zero encountered in double_scalars kan soms voorkomen, dat is niet per se een probleem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CPT_fit(params, games, choices):\n",
    "    alpha, beta, labda, gamma, theta = params\n",
    "    l, m = games.shape[1], games.shape[1] // 4\n",
    "    \n",
    "    # calculate subjective values based\n",
    "    sub_outcomes = vec_sub_value(games[:, range(1,l,2)], alpha, beta, labda) # o1, o2, o3, o4\n",
    "    \n",
    "    # calculate subjectieve probabilities\n",
    "    sub_probs = vec_prob_weight(games[:, range(0,l,2)], gamma) # p1, p2, p3, p4\n",
    "    \n",
    "    # calculate expected values\n",
    "    expected_v = vec_EV(sub_outcomes, sub_probs)\n",
    "    \n",
    "    # calculate probability of choosing the first option\n",
    "    ss = vec_choice(np.sum(expected_v[:, :m], axis=1, keepdims=True),\n",
    "                    np.sum(expected_v[:, m:], axis=1, keepdims=True), theta)\n",
    "    \n",
    "    # make a list with probabilities of first and second option \n",
    "    ls = np.concatenate([ss, 1 - ss], axis=1)\n",
    "    \n",
    "    # select the probabilities of the choice of the subject\n",
    "    probs_of_choice = [probs[choice-1] for probs, choice in zip(ls, choices)]\n",
    "    \n",
    "    return -1 * np.sum(np.log(probs_of_choice))\n",
    "\n",
    "\n",
    "\n",
    "vec_choice = np.vectorize(cpt_choice, excluded=[2])\n",
    "\n",
    "with open(\"data_LC4.txt\") as f:\n",
    "    data = np.loadtxt(f, dtype=float, delimiter=\"\\t\", skiprows=1)\n",
    "\n",
    "games = data[:,3:11]               # p1, o1, p2, o2, p3, o3, p4, o4\n",
    "choices = data[:, 12].astype(int)  # 1 or 2\n",
    "\n",
    "fit = optimize.minimize(CPT_fit, x0 = np.array([0.5, 0.5, 0.5, 0.5, 0.05]),\n",
    "                        method='Nelder-Mead', args=(games, choices)) \n",
    "\n",
    "print(fit.message, '\\nNumber of iters:',fit.nit, '\\nOptimisation succes?', fit.success, '\\n\\nParametervalues:')\n",
    "var = ['alpha', 'beta', 'lambda', 'gamma', 'theta']\n",
    "for i in range(5):\n",
    "    print(var[i]+\" = %.5f\" % fit.x[i])\n",
    "    \n",
    "print('\\n',fit.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welke parameterwaarden fitten de data van de proefpersonen het beste? En als we deze parameters voor waar aannemen, hoe kijken deze proefpersonen tegen winsten en verliezen aan? Hoe weegt deze persoon waarschijnlijkheden? (oftwel beschrijf de parameter waardes in normale mensen taal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q4.b (4 pts)\n",
    "Maak gebruik van bovenstaande functie en fit die op je eigen data `studentnummer_data.txt`. Wat zijn jouw parameter schattingen en wat betekenen die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Antwoord*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4b: Prisoners Dilemma Competitie\n",
    "We hebben in het college over social decision-making onder andere het prisonders dilemma game besproken. Kijk het voor de zekerheid nog een keer na. We gaan het nu met z'n allen spelen en dat is ook deel 2 van het huiswerk. Open hiervoor het `Assignment_4b_Competition.ipynb` in de competition map."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
